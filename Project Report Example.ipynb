{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project to Compare Learning Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*by Alex Laswell and Damian Armijo, May 9, 2018*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially we had chosen to simply code a game of snake in python that uses the Q Reinforcement Method described in class and the final programming assignment. However, in researching reinforcement learning methods and the Q method in particular, it became apparent that this horse has been beat to death."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we chose to take some of the better models that we found and preform an analysis of which method preformed the best out of the following three:\n",
    "\n",
    "* A Simple Neural Network\n",
    "* Deep Reinforcement Learning (DQN)\n",
    "* State-action-reward-state-action (SARSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code repositories / concepts were utilized for testing and analysis. \n",
    "\n",
    "* [Neural Network by Slava Korolev](https://towardsdatascience.com/today-im-going-to-talk-about-a-small-practical-example-of-using-neural-networks-training-one-to-6b2cbd6efdb3)\n",
    "* [DQN by Yuriy Guts](https://github.com/YuriyGuts/snake-ai-reinforcement)\n",
    "* [SARSA by Pranesh Srinivasan](http://spranesh.github.io/rl-snake/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We both worked on this together every step of the way; researching which methods and code repositories we wanted to evalutate, running the code in the testing environment, compiling the data, and writting up our findings. We meet at least once each week, sometimes twice, and really just treated this as a team project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our testing, we found that SARSA peformed better than either of the other methods. However it does take a lot more time to  train than either of the other methods.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, DQN does better than the simple nerual network, which was consistant with our expectations. However, we both were pretty confident that this was going to be the best method, and our findings proved otherwise. When the training time was shortened, both Q-Learning and SARSA preformed about the same, with Q-Learning even out preforming the SARSA sometimes, but this is only if the training time is very short (like 20-25 minutes), anything after that and SARSA takes over. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the algorithms did show learning even with just a handfull of iterations, 2-3  minutes of training or about one hundred games. Which again was consistent with our expectations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I learned.  What was difficult.  Changes I had to make to timeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Goodfellow, et al., 2016] Ian Goodfellow and Yoshua Bengio and Aaron Courville, [Deep Learning](http://www.deeplearningbook.org), MIT Press. 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Your report for a single person team should contain approximately 2,000 to 5,000 words, in markdown cells.  You can count words by running the following python code in your report directory.  Projects with two people, for example, should contain 4,000 to 8,000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count for file Project Report Example.ipynb is 163\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from IPython.nbformat import current\n",
    "import glob\n",
    "nbfile = glob.glob('Project Report Example.ipynb')\n",
    "if len(nbfile) > 1:\n",
    "    print('More than one ipynb file. Using the first one.  nbfile=', nbfile)\n",
    "with io.open(nbfile[0], 'r', encoding='utf-8') as f:\n",
    "    nb = current.read(f, 'json')\n",
    "word_count = 0\n",
    "for cell in nb.worksheets[0].cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "print('Word count for file', nbfile[0], 'is', word_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
